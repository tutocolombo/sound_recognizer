# Environmental Sound Classifier

Implementation of an end to end machine learning project using the following:

- Code quality assurance with pre-commit hooks, GitHub Actions (WIP), and pytest
- Model implementation in PyTorch
- Model training and basic tracking and metrics via PyTorch Lightning and torchmetrics
- Experiment tracking, hyperparameter tuning, and model versioning with W&B
- Model packaging in TorchScript
- Predictor backend containerization via Docker and deployment as a microservice on AWS Lambda
- Pure Python frontend web application in Gradio, tunneled with Ngrok. In Docker containers, running on an EC2 instance

## Data

The model was trained on the
[ESC-50: Dataset for Environmental Sound Classification](https://github.com/karolpiczak/ESC-50).  
PyTorch Lightning Dataset and Datamodule implemented for this particular dataset.

## Training

The model is a pretrained resnet, modified and fine-tuned for the task. Nothing fancy here.
The audio was converted to Mel Spectrogram before being fed to the model.

## Usage

You can check the running model on the link in the about section. If you want to reproduce any part of the process,
here is a quick rundown.

### Installation
This was developed using Python 3.8. once you have a python virtual environment, You can install all dependencies with

    make pip-tools

### Data
You can explore the dataset with python. Check the 'data explore' notebook for an example.

### Model training
If you have a gpu available you can run an experiment train of the model with

    python training/run_experiment.py --batch_size 64 --accelerator='gpu' --devices=1 --max_epochs 50 --log_every_n_steps 5
You can add `--wandb` to the command to log results and artifacts to Weights and Biases for future use. (Requires login to W&B)

### Model staging
Using one of the artifacts generated by the training experiment, we can package it with torchscript using

    python training/stage_model.py --entity=DEFAULT --run=RUN_ID --ckpt_alias=ALIAS
With run_id and alias the id of the run and the alias of the artifact that was logged in the previous step.

Check 'experiment' notebook for an example of this.

### App
The packaged and containerized model is running in AWS lambda.
You can run the front end in your localhost pointing it to the model url with

    python app_gradio/app.py --model_url https://26bc2iygctv2z6mrhw7tkmvfhi0rpavp.lambda-url.ap-southeast-2.on.aws/

You can add `--flagging` to get the option to flag predictions of the model as incorrect,
but this requires s3 credentials. (the flagged examples are sent to a bucket for later analysis)

## Credits

[FSDL 2022](https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2022-labs)

[torchaudio.dataset.ESC-50](https://github.com/AminJun/torchaudio.dataset.ESC-50)

